from tensorflow.keras.models import load_model
import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image
import io
from streamlit_webrtc import webrtc_streamer
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration, VideoProcessorBase
import cv2
from pred import pred_expression, webcam_expression
from streamlit_webrtc import webrtc_streamer
import av
from urllib.request import Request, urlopen
from img_file import images_and_captions


# í˜ì´ì§€ì˜ ë„ˆë¹„ë¥¼ ì„¤ì •
# st.set_page_config(layout="wide")
st.set_page_config(layout="centered")  # - ì´ ì½”ë“œëŠ” ì „ì²´ì ìœ¼ë¡œ ê°€ìš´ë° ì •ë ¬ì„ í•´ì£¼ëŠ” ì½”ë“œ.

# í”„ë¡œê·¸ë¨ ì œëª©
st.title("ğŸŒ» ğŸŒ¼ ğŸ’ ê°ì • ì¸ì‹ êµêµ¬ ğŸŒ¹ ğŸŒº ğŸŒ¸")
st.write("ì´ í”„ë¡œê·¸ë¨ì€ ìíì•„ë™ì„ ëŒ€ìƒìœ¼ë¡œ ê°ì • ì¸ì‹ì„ ë„ì™€ì£¼ê¸° ìœ„í•œ êµêµ¬ì…ë‹ˆë‹¤.")
st.divider()
# ìƒˆë¡œìš´ ì‚¬ì´ë“œë°” (ìµœì¢…)
# Sidebarì— í‘œì‹œí•  ì¹´í…Œê³ ë¦¬ ëª©ë¡
with open('./streamlit/style.css') as f:
    st.markdown(f'<style>{f.read()}', unsafe_allow_html=True) 

categories = ["T r a i n  â›³ï¸", "T e s t  ğŸ’¯", "T r y  ğŸª"]
# Sidebarì— ì¹´í…Œê³ ë¦¬ ì„ íƒì„ ìœ„í•œ ë¼ë””ì˜¤ ë²„íŠ¼ ì¶”ê°€
selected_category = st.sidebar.radio("ê°ì • ì¸ì‹ êµêµ¬", categories)


############################################################################################################################################################################

# í›ˆë ¨ í˜ì´ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
def show_training_page():
    st.subheader("ì‚¬ì§„ì„ ë³´ê³ , ì–´ë–¤ ê°ì •ì¸ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    

    # í˜„ì¬ ì´ë¯¸ì§€ ë° ìº¡ì…˜ì˜ index
    current_index = st.session_state.get('current_index', 7)

    # ì´ë¯¸ì§€ì™€ ë²„íŠ¼ì„ ë°°ì¹˜í•˜ëŠ” ì—´ ìƒì„±í•˜ê¸°
    col1, col2, col3 = st.columns([1, 15, 1])

    with col1:
        # st.write('    ')
        # st.write('    ')
        # st.write('    ')
        # st.write('    ')
        # st.write('    ')
        # "ì´ì „" ë²„íŠ¼ í‘œì‹œ
        if st.button("â¬…ï¸", key="page1_left_button"):
            current_index = (current_index - 1) % len(images_and_captions)
        # st.write('    ')
        # # "ë‹¤ìŒ" ë²„íŠ¼ í‘œì‹œ
        # if st.button("ë‹¤ìŒ", key="page1_right_button"):
        #     current_index = (current_index + 1) % len(images_and_captions)
        # í˜„ì¬ ì¸ë±ìŠ¤ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ê¸°
        st.session_state.current_index = current_index

    with col3:
        # st.write('    ')
        # st.write('    ')
        # st.write('    ')
        # st.write('    ')
        # st.write('    ')
        # "ì´ì „" ë²„íŠ¼ í‘œì‹œ
        # if st.button("ì´ì „", key="page1_left_button"):
        #     current_index = (current_index - 1) % len(images_and_captions)
        # st.write('    ')
        # "ë‹¤ìŒ" ë²„íŠ¼ í‘œì‹œ
        if st.button("â¡ï¸", key="page1_right_button"):
            current_index = (current_index + 1) % len(images_and_captions)
        # í˜„ì¬ ì¸ë±ìŠ¤ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ê¸°
        st.session_state.current_index = current_index

    with col2:
        req = Request(images_and_captions[current_index]['image_url'], headers={'User-Agent': 'Mozilla/5.0'})
        pil_image = Image.open(urlopen(req))

        # PIL Imageë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
        image_np = np.array(pil_image)
        
        # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì½ê¸°
        cv_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)

        # ê²°ê³¼ ì˜ˆì¸¡
        emotion = pred_expression(cv_image)

        pil_image_resize = pil_image.resize((600, 500))

        st.image(pil_image_resize, use_column_width=True)
        st.header(f'ê°ì •: {emotion}')

############################################################################################################################################################################

# ì‹œí—˜ í˜ì´ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜

def generate_question_page(question_number):
    st.subheader(f"ë¬¸ì œ {question_number}. ì´ ì‚¬ì§„ì€ ë¬´ìŠ¨ ê°ì •ì„ ë‚˜íƒ€ë‚´ê³  ìˆë‚˜ìš”?")
    user_answer = st.text_input("ë‹µì„ ì…ë ¥í•˜ì„¸ìš”:")
    return user_answer


def show_exam_page():
    
    st.subheader("ì‚¬ì§„ì„ ë³´ê³ , ì–´ë–¤ ê°ì •ì¸ì§€ë¥¼ ë§ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # í˜„ì¬ ì´ë¯¸ì§€ ë° ìº¡ì…˜ì˜ index
    page2_current_index = st.session_state.get('current_index', 0)

    # ì´ë¯¸ì§€ì™€ ë²„íŠ¼ì„ ë°°ì¹˜í•˜ëŠ” ì—´ ìƒì„±í•˜ê¸°
    p2_col1, p2_col2 = st.columns([9, 1])



    with p2_col2:
        
        if st.button("â¡ï¸", key="page2_right_button"):
            page2_current_index = np.random.randint(len(images_and_captions)) % (len(images_and_captions)-1)
            st.session_state.current_index = page2_current_index

    with p2_col1:

        req = Request(images_and_captions[page2_current_index]['image_url'], headers={'User-Agent': 'Mozilla/5.0'})
        pil_image = Image.open(urlopen(req))

        # PIL Imageë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
        image_np = np.array(pil_image)
        
        # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì½ê¸°
        cv_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)

        # ê²°ê³¼ ì˜ˆì¸¡
        emotion = pred_expression(cv_image)

        pil_image_resize = pil_image.resize((600, 500))
        st.image(pil_image_resize, use_column_width=True)
    
    # ê°€ë¡œ ì¤„ ì„¸ìš°ê¸°
    s1 = ''
    a, p2_btn_col1, b, p2_btn_col2, c, p2_btn_col3, d = st.columns([1.5, 3, 1.5, 3, 1.5, 3, 1.5])
    with p2_btn_col1:
        if st.button('Happy'):
            if 'Happy'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    with p2_btn_col2:
        if st.button('Sad'):
            if 'Sad'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    with p2_btn_col3:
        if st.button('Neutral'):
            if 'Neutral'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    p2_btn_col4, f, p2_btn_col5, g,  p2_btn_col6, i,  p2_btn_col7 = st.columns([3, 1, 3, 1, 3, 1, 3])
    with p2_btn_col4:
        if st.button('Surprise'):
            if 'Surprise'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    with p2_btn_col5:
        if st.button('Angry'): 
            if 'Anger'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    with p2_btn_col6:
        if st.button('Fear'): 
            if 'Fear'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    with p2_btn_col7:
        if st.button('Disgust'): 
            if 'Disgust'==emotion:
                s1 = 'ğŸ‰ ğŸ‰ ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤ ğŸ‰ ğŸ‰ ğŸ‰'
                st.balloons()
            else:
                s1 = 'ì˜¤ë‹µì…ë‹ˆë‹¤ ! ë‹¤ì‹œ ë„ì „í•˜ì„¸ìš” ~'

    if s1 != '':
        st.subheader(s1)
        # st.subheader(s2)

############################################################################################################################################################################

# Self í˜ì´ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
def show_self_page():
    st.subheader("Webcamê³¼ ì‚¬ì§„ì„ í™œìš©í•˜ì—¬ ê°ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # webcam ê³¼ upload tab ë‚˜ëˆ„ê¸°
    tab1, tab2 = st.tabs(['Webcam', 'Upload'])
    # webcam tab
    with tab1:
        # webrtc_ctx = \
        webrtc_streamer(key="example", 
                        video_frame_callback=webcam_expression,
                        async_processing=True)
        
    # upload tab
    with tab2:
        st.write("Image :camera:")

        uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
        if uploaded_file is not None:
            # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ
            pil_image = Image.open(uploaded_file)

            # PIL Imageë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
            image_np = np.array(pil_image)
            
            # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì½ê¸°
            cv_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)

            # ê²°ê³¼ ì˜ˆì¸¡ í›„ ì¶œë ¥
            emotion = pred_expression(cv_image)
            st.title(f'{emotion}')
            
            st.image(image_np, use_column_width=True)


# Streamlit ì•± ì‹¤í–‰
if __name__ == "__main__":
    # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í˜ì´ì§€ í‘œì‹œ
    if selected_category == "T r a i n  â›³ï¸":
        show_training_page()
    elif selected_category == "T e s t  ğŸ’¯":
        show_exam_page()
    elif selected_category == "T r y  ğŸª":
        show_self_page()


############################################################################################################################################################################


# def get_data():
#     print("get_data")
#     df = pd.DataFrame({"A": np.arange(0, 10, 1), "B": np.arange(0, 1, 0.1)})
#     return df

