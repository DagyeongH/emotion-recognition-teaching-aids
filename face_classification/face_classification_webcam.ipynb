{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMS2BvAw9GwAEID6UQ5xneu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gDMOSmlfz9o_"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","# 데이터 확인\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Dataset 만들기\n","import keras\n","from keras.utils import to_categorical\n","\n","# Detect Face\n","import cv2\n","from scipy.ndimage import zoom\n","\n","# Model\n","import torch\n","from keras.models import Sequential\n","# from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","# from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","# from keras.layers.normalization import batch_normalization\n","from tensorflow.keras.models import Sequential\n","\n","from keras.models import Model\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBYTegwi0Bso","executionInfo":{"status":"ok","timestamp":1700149624247,"user_tz":-540,"elapsed":19946,"user":{"displayName":"최기원","userId":"01859623484991989729"}},"outputId":"9a70a3dc-ea68-4952-b022-3e22214ed35a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/last/im"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEpVozIJ0HeG","executionInfo":{"status":"ok","timestamp":1700149641861,"user_tz":-540,"elapsed":3,"user":{"displayName":"최기원","userId":"01859623484991989729"}},"outputId":"9b46de38-18b2-41b3-913c-622ba6afcc4b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/last/im\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JXEqs-qo0TJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shape_x = 48\n","shape_y = 48\n","\n","# 전체 이미지에서 얼굴을 찾아내는 함수\n","def detect_face(frame):\n","\n","    # cascade pre-trained 모델 불러오기\n","    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","\n","    # RGB를 gray scale로 바꾸기\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # cascade 멀티스케일 분류\n","    detected_faces = face_cascade.detectMultiScale(gray,\n","                                                   scaleFactor = 1.1,\n","                                                   minNeighbors = 6,\n","                                                   minSize = (shape_x, shape_y),\n","                                                   flags = cv2.CASCADE_SCALE_IMAGE\n","                                                  )\n","\n","    coord = []\n","    for x, y, w, h in detected_faces:\n","        if w > 100:\n","            sub_img = frame[y:y+h, x:x+w]\n","            coord.append([x, y, w, h])\n","\n","    return gray, detected_faces, coord"],"metadata":{"id":"fXfZP9HS0M0h","executionInfo":{"status":"ok","timestamp":1700149661549,"user_tz":-540,"elapsed":278,"user":{"displayName":"최기원","userId":"01859623484991989729"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 전체 이미지에서 찾아낸 얼굴을 추출하는 함수\n","def extract_face_features(gray, detected_faces, coord, offset_coefficients=(0.075, 0.05)):\n","    new_face = []\n","    for det in detected_faces:\n","\n","        # 얼굴로 감지된 영역\n","        x, y, w, h = det\n","\n","        # 이미지 경계값 받기\n","        horizontal_offset = np.int(np.floor(offset_coefficients[0] * w))\n","        vertical_offset = np.int(np.floor(offset_coefficients[1] * h))\n","\n","        # gray scacle 에서 해당 위치 가져오기\n","        extracted_face = gray[y+vertical_offset:y+h, x+horizontal_offset:x-horizontal_offset+w]\n","\n","        # 얼굴 이미지만 확대\n","        new_extracted_face = zoom(extracted_face, (shape_x/extracted_face.shape[0], shape_y/extracted_face.shape[1]))\n","        new_extracted_face = new_extracted_face.astype(np.float32)\n","        new_extracted_face /= float(new_extracted_face.max()) # sacled\n","        new_face.append(new_extracted_face)\n","\n","    return new_face"],"metadata":{"id":"UBed1vG-0R0P","executionInfo":{"status":"ok","timestamp":1700149695570,"user_tz":-540,"elapsed":979,"user":{"displayName":"최기원","userId":"01859623484991989729"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import keras\n","import cv2"],"metadata":{"id":"kieUIWCv09G7","executionInfo":{"status":"ok","timestamp":1700149867378,"user_tz":-540,"elapsed":798,"user":{"displayName":"최기원","userId":"01859623484991989729"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 모델 불러오기\n","model = keras.models.load_model('/content/drive/MyDrive/last/model.h5')\n","\n","# 인덱스번호로 웹캠연결 대부분 시스템적으로 0번부터 부여됨\n","video_capture = cv2.VideoCapture(0)"],"metadata":{"id":"gmmg865R0Y2m","executionInfo":{"status":"ok","timestamp":1700149869982,"user_tz":-540,"elapsed":375,"user":{"displayName":"최기원","userId":"01859623484991989729"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 프레임 단위로 영상 캡쳐\n","while True:\n","    ret, frame = video_capture.read()\n","    # ret: 비디오를 성공적으로 읽어왔는지 확인 True/False\n","    # frame: 각 픽셀의 색상을 포함한 프레임 정보 Numpy\n","\n","    face_index = 0\n","    gray, detected_faces, coord = detect_face(frame)\n","\n","    try:\n","        face_zoom = extract_face_features(gray, detected_faces, coord)\n","        face_zoom = np.reshape(face_zoom[0].flatten(), (1, 48, 48, 1))\n","        x, y, w, h = coord[face_index]\n","\n","        # 머리 둘레에 직사각형 그리기: (0, 255, 0)을 통해 녹색으로 선두께는 2\n","        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","        # 감정 예측\n","        pred = model.predict(face_zoom)\n","        pred_result = np.argmax(pred)\n","\n","        # 각 라벨별 예측 정도 표시\n","        cv2.putText(frame,                                   # 텍스트를 표시할 프레임\n","                    \"Angry: \" + str(round(pred[0][0], 3)),   # 텍스트 표시 \"감정: 예측 probablity\", 소수점 아래 3자리\n","                    (10, 50),                                # 텍스트 위치\n","                    cv2.FONT_HERSHEY_SIMPLEX,                # 폰트 종류\n","                    1,                                       # 폰트 사이즈\n","                    (0, 0, 255),                             # 폰트 색상\n","                    2                                        # 폰트 두께\n","                   )\n","        cv2.putText(frame, \"Disgust: \" + str(round(pred[0][1], 3)), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","        cv2.putText(frame, \"Fear: \" + str(round(pred[0][2], 3)), (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","        cv2.putText(frame, \"Happy: \" + str(round(pred[0][3], 3)), (10, 170), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","        cv2.putText(frame, \"Sad: \" + str(round(pred[0][4], 3)), (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","        cv2.putText(frame, \"Surprise: \" + str(round(pred[0][5], 3)), (10, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","        cv2.putText(frame, \"Neutral: \" + str(round(pred[0][6], 3)), (10, 290), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","        # 예측값이 높은 라벨 하나만 프레임 옆에 표시\n","        if pred_result == 0:\n","            cv2.putText(frame, \"Angry \" + str(round(pred[0][0], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","        elif pred_result == 1:\n","            cv2.putText(frame, \"Disgust \" + str(round(pred[0][1], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","        elif pred_result == 2:\n","            cv2.putText(frame, \"Fear \" + str(round(pred[0][2], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","        elif pred_result == 3:\n","            cv2.putText(frame, \"Happy \" + str(round(pred[0][3], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","        elif pred_result == 4:\n","            cv2.putText(frame, \"Sad \" + str(round(pred[0][4], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","        elif pred_result == 5:\n","            cv2.putText(frame, \"Surprise \" + str(round(pred[0][5], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","        else:\n","            cv2.putText(frame, \"Neutral \" + str(round(pred[0][6], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n","\n","    except:\n","        continue\n","\n","    # 결과 표시\n","    cv2.imshow('Video', frame)\n","\n","    # 사용자가 q 키를 누르면 종료\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# 웹캠 해지\n","video_capture.release()\n","\n","# 창 닫기: 창이 안닫히는 경우 쥬피터 닫기\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"vBVwZECg0SlM","executionInfo":{"status":"error","timestamp":1700149891810,"user_tz":-540,"elapsed":4,"user":{"displayName":"최기원","userId":"01859623484991989729"}},"outputId":"19f2966d-ec9e-4be6-8cf5-26d0eb28ac92"},"execution_count":11,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-060189c6565f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mface_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-7f8f4a5e706e>\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# RGB를 gray scale로 바꾸기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# cascade 멀티스케일 분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]}]}